{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while instantiating 'org.apache.spark.sql.hive.HiveSessionStateBuilder':\n",
      "org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$instantiateSessionState(SparkSession.scala:1053)\n",
      "\t at org.apache.spark.sql.SparkSession$$anonfun$sessionState$2.apply(SparkSession.scala:130)\n",
      "\t at org.apache.spark.sql.SparkSession$$anonfun$sessionState$2.apply(SparkSession.scala:130)\n",
      "\t at scala.Option.getOrElse(Option.scala:121)\n",
      "\t at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:129)\n",
      "\t at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:126)\n",
      "\t at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\t at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\t at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\t at java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\t at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\t at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\t at py4j.Gateway.invoke(Gateway.java:280)\n",
      "\t at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\t at py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\t at py4j.GatewayConnection.run(GatewayConnection.java:214)\n",
      "\t at java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "try:\n",
    "    sc.stop()\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Twitter\") \\\n",
    "        .config(\"master\", \"spark://115.146.92.120:7077\") \\\n",
    "        .getOrCreate()\n",
    "except Exception,err:\n",
    "    print err.desc\n",
    "    print err.stackTrace\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Pi is roughly 3.166400\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print \"start\"\n",
    "def inside(p):\n",
    "    x, y = random.random(), random.random()\n",
    "    return x*x + y*y < 1\n",
    "\n",
    "count = sc.parallelize(xrange(0, 10000),4) \\\n",
    "             .filter(inside).count()\n",
    "print \"Pi is roughly %f\" % (4.0 * count / 10000)\n",
    "\n",
    "print sc.defaultParallelism\n",
    "print sc._jsc.sc().getExecutorMemoryStatus().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-753fcfa9f9ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hdfs://115.146.92.120:9000/user/ubuntu/bigTwitter.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = sc.read.json(\"hdfs://115.146.92.120:9000/user/ubuntu/bigTwitter.json\")\n",
    "js = df.select(\"json\")\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
